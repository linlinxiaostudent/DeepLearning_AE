{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datascience.csv',encoding = 'gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>大数据产业迎政策暖风 最新大数据概念股一览</td>\n",
       "      <td>财经热点扒客</td>\n",
       "      <td>大数据产业发展受到国家重视，而大数据已经上升为国家战略，未来发展前景很广阔。大数据产业“十三...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google发布机器学习平台Tensorflow游乐场～带你一起玩神经网络！</td>\n",
       "      <td>硅谷周边</td>\n",
       "      <td>点击上方“硅谷周边”关注我，收到最新的文章哦！昨天，Google发布了Tensorflow游...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>李克强：中国大数据和云计算产业是开放的</td>\n",
       "      <td>苏州高新区金融办</td>\n",
       "      <td>国务院总理李克强当地时间20日上午在纽约下榻饭店同美国经济、金融、智库、媒体等各界人士座谈，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>全峰集团持续挖掘大数据</td>\n",
       "      <td>快递物流网</td>\n",
       "      <td>2016年，全峰集团持续挖掘大数据、云计算、“互联网+”等前沿技术和物流快递的融合，并通过优...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>第366期【微理工】贵州理工学院召开大数据分析与应用专题分享会</td>\n",
       "      <td>贵州理工学院</td>\n",
       "      <td>贵州理工学院召开大数据分析与应用专题分享会 借“创响中国”贵安站巡回接力活动暨2016贵安大...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title    author  \\\n",
       "0                   大数据产业迎政策暖风 最新大数据概念股一览    财经热点扒客   \n",
       "1  Google发布机器学习平台Tensorflow游乐场～带你一起玩神经网络！      硅谷周边   \n",
       "2                     李克强：中国大数据和云计算产业是开放的  苏州高新区金融办   \n",
       "3                             全峰集团持续挖掘大数据     快递物流网   \n",
       "4         第366期【微理工】贵州理工学院召开大数据分析与应用专题分享会    贵州理工学院   \n",
       "\n",
       "                                             content  \n",
       "0  大数据产业发展受到国家重视，而大数据已经上升为国家战略，未来发展前景很广阔。大数据产业“十三...  \n",
       "1  点击上方“硅谷周边”关注我，收到最新的文章哦！昨天，Google发布了Tensorflow游...  \n",
       "2  国务院总理李克强当地时间20日上午在纽约下榻饭店同美国经济、金融、智库、媒体等各界人士座谈，...  \n",
       "3  2016年，全峰集团持续挖掘大数据、云计算、“互联网+”等前沿技术和物流快递的融合，并通过优...  \n",
       "4  贵州理工学院召开大数据分析与应用专题分享会 借“创响中国”贵安站巡回接力活动暨2016贵安大...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chinese_word_cut(mytext):\n",
    "    return ' '.join(jieba.cut(mytext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\lulinlin\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.099 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "df['content_cutted']= df.content.apply(chinese_word_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    大 数据 产业 发展 受到 国家 重视 ， 而 大 数据 已经 上升 为 国家 战略 ， 未...\n",
       "1    点击 上方 “ 硅谷 周边 ” 关注 我 ， 收到 最新 的 文章 哦 ！ 昨天 ， Goo...\n",
       "2    国务院 总理 李克强 当地 时间 20 日 上午 在 纽约 下榻 饭店 同 美国 经济 、 ...\n",
       "3    2016 年 ， 全峰 集团 持续 挖掘 大 数据 、 云 计算 、 “ 互联网 + ” 等...\n",
       "4    贵州 理工学院 召开 大 数据分析 与 应用 专题 分享 会   借 “ 创响 中国 ” 贵...\n",
       "Name: content_cutted, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.content_cutted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer\n",
    "n_features=1000\n",
    "tf_vectorizer = CountVectorizer(strip_accents ='unicode',\n",
    "                               max_features= n_features,\n",
    "                               stop_words='english',\n",
    "                                max_df = 0.5,\n",
    "                                min_df=10)\n",
    "tf=tf_vectorizer.fit_transform(df.content_cutted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "n_topics=5\n",
    "lda= LatentDirichletAllocation(n_topics = n_topics,\n",
    "                                  max_iter =50,\n",
    "                                  learning_method = 'online',\n",
    "                                  learning_offset=50.,\n",
    "                                  random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lulinlin\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=50, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=1, n_topics=5, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic#0：\n",
      "网络 深度 一种 工具 基于 分类 训练 数据库 不同 系统 计算 处理 特征 神经网络 可视化 机器 方法 算法 使用 模型\n",
      "Topic#1：\n",
      "孩子 已经 非常 所以 用户 现在 时候 一些 因为 这样 但是 不是 什么 很多 自己 没有 他们 如果 可能 就是\n",
      "Topic#2：\n",
      "需求 价值 工作 产业 能力 系统 实现 客户 创新 金融 产品 用户 业务 数据分析 行业 公司 互联网 管理 服务 平台\n",
      "Topic#3：\n",
      "12 20 同比 全国 美国 应当 阅读 其中 或者 30 检索 人口 关注 2015 城市 市场 10 增长 电子 2016\n",
      "Topic#4：\n",
      "服务 方面 百度 语音 目前 计算机 系统 医疗 已经 识别 未来 研究 深度 公司 人类 机器 机器人 智能 领域 学习\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model,feature_names,n_top_words):\n",
    "    for topic_idx,topic in enumerate(model.components_):\n",
    "        print('Topic#%d：' % topic_idx)\n",
    "        print(' '.join([feature_names[i] for i in topic.argsort()[-n_top_words-1:-1]]))\n",
    "    print('\\n')\n",
    "n_top_words =20\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda,tf_feature_names,n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, pyLDAvis.show() is not the best command\n",
      "      to use. Consider using pyLDAvis.display(), or pyLDAvis.enable_notebook().\n",
      "      See more information at http://pyLDAvis.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8889/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Jan/2018 16:22:22] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [14/Jan/2018 16:22:22] \"GET /LDAvis.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [14/Jan/2018 16:22:22] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [14/Jan/2018 16:22:22] \"GET /LDAvis.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.sklearn.prepare(lda, tf, tf_vectorizer)\n",
    "data = pyLDAvis.sklearn.prepare(lda, tf, tf_vectorizer)\n",
    "pyLDAvis.show(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
